---
title: "How to visualize models, their assumptions and post-hocs"
description: |
 A picture is worth a thousand words! This article shows how to visualize results of 16 different models in R: from a simple linear model to a multiple-additive-non-linear-mixed-effects model. Among them are logistic, multinomial, additive and survival models with and without interactions. **Goal: minimum R code & maximum output!** We'll also go a bit beyond only model visualization. So, don't miss the bonuses ðŸ˜‰.
author:
  - name: Yury Zablotski
    url: https://yury-zablotski.netlify.app/
date: 01-01-2021
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_float: true
    code_download: true
#draft: true
categories:
  - visualization
  - videos
  - models
preview: thumbnail_visualize_models.png
  
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F)
```





# A demo for the first 7 linear models

Two YouTube videos in this article demonstrate the code presented below and explain all you need to know. Thus, I reduced the text to a minimum in order to decrease redundancy. If you still have a question, drop me a comment on YouTube or on this article below. I'll try to respond as quick as I can.

```{r, eval=T, echo=F}
vembedr::embed_youtube("BNTn_f43U04")
```


Let's get our first data. We'll use several dataset through out this article.


```{r}
# install.packages("tidyverse") 
# install.packages("ISLR") 
library(tidyverse) # data wrangling
library(ISLR)      # get "Wage" dataset

# reproducibility: the same seed grows the same tree
set.seed(1)        

d <- Wage %>%
  sample_n(1000) %>% 
  rename(salary = wage) 

# have a look at the data
glimpse(d)
```

## 1. Simple linear model with one categorical predictor

The *effects()* package is the main visualization package we'll use. It can visualize results of almost any model. We'll start with the visualization of predicted values.

```{r}
m <- lm(salary ~ jobclass, d)

# install.packages("effects")
library(effects)    # for model visualization & more

plot(allEffects(m))
```



## 2. Simple linear model with one numeric predictor

Here we'll add *grid = TRUE* for a better readability, so that we don't need to stare on the y-axis and guess the result.

```{r}
m <- lm(salary ~ age, d)

plot(allEffects(m), grid = TRUE)
```



## 3. Multiple linear model with several categorical predictors

We can visualize all predictors at once, or any particular predictor from a multiple model individually.

```{r}
m <- lm(salary ~ jobclass + education, d)

plot(allEffects(m))

plot(predictorEffect(predictor = "education", mod = m))
```



## 4. Multiple linear model with several numeric predictors

Here we'll see how to change the appearance of confidence intervals and introduce another amazing model-visualization package - *sjPlot*. In this chapter we'll use the *effects* package for the visualization of the predicted values and *sjPlot* package for the visualization of the estimates with their confidence intervals.

```{r}
m <- lm(salary ~ age + year, d)

plot(allEffects(m))
plot(allEffects(m), confint=list(style="bars"))

# install.packages("sjPlot")
library(sjPlot)    # for model visualization
plot_model(m)
```



## 5. Multiple linear model with numeric and categorical predictors

We can change design of the plot by determining the number of *rows* and *columns* in the *plot(allEffects())*. The *plot_model()* function can also display the numeric values of the estimates and the significance stars, which is often all we need. Besides, it looks much better than a table-looking output of the model results.

```{r}
m <- lm(salary ~ age + education, d)

plot(allEffects(m))
```


```{r fig.height=7}
plot(allEffects(m), rows = 2, cols = 1)
```


```{r fig.width=7}
plot_model(m, show.values = TRUE)
```


# Bonus 1: check all the assumption in one line of code

*check_model* is just awesome! One of my favorite R functions! I get a "**nerdgasm**" every time I use it ðŸ˜‚. The video explains it very well.

```{r fig.height=9}
# install.packages("performance")
library(performance)    # model assumptions & performance
check_model(m)
```



## 6. Multiple linear model with interactions 

First of all, the *allEffects()* functions visualizes interactions easily! Secondly, we can put several lines on the same plot with or without confidence intervals by using argument *multiline = TRUE*. "T" instead of "TRUE" also works. The *sjPlot* package is not only able to also easily visualize interactions, but can in addition be extended with the usual *ggplot2* syntax, which can greatly improve the appearance of the plot. 

```{r}
m <- lm(salary ~ education * jobclass, d)

# not too neat representation!
plot(allEffects(m))

# better representation
plot(allEffects(m), lines = list(multiline = TRUE))
```


```{r fig.width=8}
# perfect representation
plot(
  allEffects(m), 
  lines = list(multiline = T), 
  confint = list(style = "auto"))

plot_model(m, type = "int")+theme_blank()+theme(legend.position = "top")
```



# Bonus 2: easy post-hocs

The *emmeans* package is one of my favorite for conducting post-hocs. In this chapter we only display the results in the text/table form. Later we'll also visualize post-hocs.

```{r}
# install.packages("emmeans")
library(emmeans)      # for post-hocs
emmeans(m, pairwise ~ jobclass | education, adjust = "fdr")$contrasts
```



## 7. Multiple linear model with interactions bwtween numeric predictors

```{r}
m <- lm(salary ~ age * health, d)

plot(
  allEffects(m), 
  lines = list(multiline = T), 
  confint = list(style = "auto"))

plot_model(m, type = "int")+
  theme_minimal()+
  theme(legend.position = "top")
```


```{r fig.height=9}
check_model(m)
```


# Bonus 3: quick multiple models with ggplot

We do not always need to explicitly model things in order to explore our data. A *geom_smooth()* function from *ggplot2* package will automatically fit numeric data. Mostly with non-linear models (e.g. GAM), but the argument *method="lm"* can force it to take the linear one. Moreover, we could also use any formula inside of the *geom_smooth()*, but if we need to write the formula anyway, we'd rather produce an explicit model. However, the code presented below is quick and easy, and therefore very practical! On this note we'll enter the world of non-linear models and I recommend to watch the second video first, before checking out the code.

```{r fig.height=9}
ggplot(d, aes(age, salary))+
  geom_point()+
  geom_smooth()+    # the quickest way to model numeric data
  facet_grid(education~jobclass, scales = "free") # quick multiple model 
```




# A demo for the next 9 models: non-linear, logistic, multinomial, mixed-effects, survival...

```{r, eval=T, echo=F}
vembedr::embed_youtube("wev5a3rwsvo")
```



## 8. Multiple non-linear polynomial model with interactions

The *allEffects* function can also easily handle polynomial non-linear models. In contrast, the *plot_model* function can't. However, we still can plot the estimates.

```{r}
m <- lm(log(salary) ~ poly(age, 2) * health, d)

plot(
  allEffects(m), 
  lines = list(multiline = T), 
  confint = list(style = "auto"))

plot_model(m, show.values = T)+
  theme_bw()
```


```{r fig.height=9}
check_model(m)
```



## 9. Multiple non-linear Generalized Additive Models (GAM)


There are two main GAM packages: *gam* and *mgcv*. They both have an identical function which we need - *gam()*, which produces a conflict and R might be confused about it. Thus, use *gam::gam()* to specify from which package exactly the *gam()* function should be used. The *gam* package has it's own plotting function - *plot.Gam* and you can display all subplots on one plot by using *par(mfrow = c(2, 2))*. Please, don't use "plot(allEffects(gam1))" for GAM models, since it will produce only linear results.

*s()* function indicates that we would like to use smoothing splines. 

```{r fig.height=7}
# install.packages("gam")
library(gam)

gam1 <- gam::gam(salary~s(year, df = 4)+s(age, df = 5)+education + jobclass, data=d)

par(mfrow = c(2, 2) )
plot.Gam(gam1 , se=TRUE, col= "blue")
```





## 10. Multiple logistic regression with interactions

Interactions in logistic regression are not a problem for both packages. Moreover, have a look at three different displays of post-hocs from the same model and find code differences. Hint: I love the "|" part of it! 

```{r}
m <- glm(health ~ jobclass * health_ins, d, family = binomial)

plot(allEffects(m))

plot_model(m, type = "int")

emmeans(m, pairwise ~ jobclass | health_ins, adjust = "fdr")$contrasts
emmeans(m, pairwise ~ health_ins | jobclass, adjust = "fdr")$contrasts
```


```{r}
emmeans(m, pairwise ~ health_ins * jobclass, adjust = "fdr")$contrasts
```


# Bonus 4: visualize the post-hoc analysis with the PairWise P-value Plot (pwpp)

As promised, here is the visualization of the post-hocs. Notice the marginal means on the y axis and color-coded design of the plot, which connects the pairs the p-values for which were calculated and adjusted (x-axis).

```{r}
pwpp(emmeans(m, ~ health_ins * jobclass), type = "response", adjust = "fdr"
     )+theme_minimal()
```



## 11. Multinomial logistic regression models via neural networks

No special treatment of the fancy neural networks needed. *plot(allEffects())* just works!

```{r fig.height=9}
# get the data
d <- foreign::read.dta("https://stats.idre.ucla.edu/stat/data/hsbdemo.dta")

m <- nnet::multinom(prog ~ ses + write, d)

plot(allEffects(m), 
     lines = list(multiline = T), 
     confint = list(style = "auto"), rows = 2, cols = 1)
```




## 12. Multiple Linear Mixed-Effects-Model with interactions

The mixed-effects models are very complex. But fortunately, all 4 main functions, namely *plot(allEffects())*, *plot_model()*, *emmeans()* and *check_model()* work flawlessly and **simply deliver!** The *check_model()* even checks the assumptions for the random effects! The random effects themselves can also be visualized, but they are rarely interpreted, so, why bother?

```{r}
# install.packages("lme4")
# install.packages("lmerTest")

library(lme4)
library(lmerTest)

# get the data
set.seed(9)
d <- InstEval %>% 
  group_by(service, studage) %>% 
  sample_n(100) %>% 
  mutate(dept = as.numeric(dept))

m1 <- lmer(y ~ service * studage + (1|s) + (1|d), data=d)

plot(
  allEffects(m1), 
  lines = list(multiline = T), 
  confint = list(style = "auto"))

plot_model(m1, type = "int")+
  theme_blank()+
  theme(legend.position = "top")

# post-hocs
emmeans(m1, pairwise ~ service | studage, adjust = "none")$contrasts 
pwpp(emmeans(m1, ~ service * studage), type = "response", adjust = "none")+
  theme_minimal()
```


```{r fig.height=11, fig.width=11}
# check model assumptions
check_model(m1)
```



# Bonus 5: how to choose the best model

The *performance* package, near the already insanely useful *check_model()* function, provides a *compare_performance()* function, which compares models with multiple quality indicators, e.g. $R^2$ or AIC. It is not only more informative as compared to the *anova()* function, which is often used for model comparison, but also works much better, because it displays a warning when two models shouldn't be compared, while *anova(m, m1)* simply fails, when models aren't supposed to be compared, but can be tricked by placing the mixed effects model (m1) first. 

```{r}
m  <- lm(y ~ service * studage, data=d)
m1 <- lmer(y ~ service * studage + (1|s) + (1|d), data=d)

compare_performance(m, m1)

anova(m1, m)
```




## 13. GAMMs - Multiple Generalised Additive (non-linear) Mixed Effects Models

These kind of models are just madness, can be easily visualized though.

```{r}
# install.packages("mgcViz")
library(mgcViz)

m <- gammV(y ~ s(as.numeric(d), k = 3) + lectage, random=list(s=~1), data= InstEval %>% 
             slice(1:5000))

plot(m, allTerms = T)
```



## 14. Kaplan-Meier survival model

Survival models can be visualized with *survminer* package. Even some statistical details can be displayed. I still did not figured out how to visualize the post-hocs for survival analysis. It you know how, please let me know. Thus, I here simply provide the p-values of the post-hocs.

```{r}
# install.packages("survival")
# install.packages("survminer")
library(survival)
library(survminer)

set.seed(1)
d <- lung %>% 
  filter(ph.ecog != 3) %>% 
  sample_n(100)

m <- survfit(Surv(time, status) ~ ph.ecog, data = d)

# simple plot
ggsurvplot(m)
```


```{r fig.height=7, fig.width=7}
# fancy plot
ggsurvplot(m, 
           pval = TRUE, 
           risk.table = "abs_pct", 
           surv.median.line = "hv")
```


```{r fig.height=7}
# post-hocs for survival analysis
pairwise_survdiff(
  formula = Surv(time, status) ~ ph.ecog, data = d, p.adjust.method = "fdr"
)
```























## 15. Exponential Parametric Models

These models are very rarely used. 

```{r}
# install.packages("flexsurv")
library(flexsurv)    # for Parametric Survival Modelling

ex <- flexsurvreg(Surv(time, status) ~ factor(ph.ecog), data = d, dist="exponential")

ggsurvplot(ex)
```

  

## 16. Cox proportional hazard models

Cox models are more common as compared to the exponential models and can be visualized with a beautiful *ggforest()* plot.

```{r fig.width=7}
m <- coxph(Surv(time, status) ~ age + sex + ph.ecog, data =  d)

ggforest(m, d)
```



I hope you found this article useful. The are of coarse more interesting models out there. Thus, please let me know what kind of models you make and how you visualize them.

If you think, I missed something, please comment on it, and Iâ€™ll improve this tutorial.

## References

- One of the best places to learn R is R-Bloggers platform: http://www.R-bloggers.com 


