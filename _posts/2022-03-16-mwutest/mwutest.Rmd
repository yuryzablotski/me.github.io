---
title: "R demo | Mann-Whitney U Test = Wilcoxon Rank Sum Test | How to conduct, visualise & interpret ðŸ¥³ What happens if we use a wrong test ðŸ˜±"
description: |
  Comparing two groups with not-normally disctributed or ordinal data is the reason we need Mann-Whitney U Test instead of t-Test. So, today we'll learn (1) how to conduct and visualize Mann-Whitney U Test you saw on the thumbnail with one simple command, (2) how to interpret all statistical results on that plot and (3) why this test is sometimes called Wilcoxon Rank Sum Test and why we shouldn't use this name
author:
  - name: Yury Zablotski
    url: https://yuzar-blog.netlify.app/
date: "`r format(Sys.time(), '%B %d, %Y')`"
categories:
  - videos
  - statistics
preview: thumbnail.png
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_float: true
    toc_depth: 6
    code_download: true
bibliography: /Users/zablotski/Documents/library.bib
#csl: american-political-science-association.csl
biblio-style: apalike
link-citations: yes
linkcolor: blue
#draft: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, message = F, warning = F)
```

## This post as a video 

I recommend to watch a video first, because I highlight things I talk about. It's ca. 5 minutes long. 

```{r, eval=T, echo=F}
vembedr::embed_youtube("2sZp51etL3c")
```

## Previous topics

[Two-Samples t-Test](https://yuzar-blog.netlify.app/posts/2022-03-11-ttest/) would help.

## Get the data

```{r}
# install.packages("tidyverse")  # for everything ;)
library(tidyverse)

#install.packages("ISLR")
library(ISLR)

set.seed(5)  # for reproducibility
d <- Wage %>% 
  group_by(jobclass) %>% 
  sample_n(15)
```



{ISLR} package provides a {Wage} dataset, with salaries of IT and industrial workers. We'll take 15 random people from every group and compare their salaries in order to figure out who ears more.

## Check normality

But before using a nonparametric Mann-Whitney U Test, **we have to make sure that our data is really not-normally distributed**. Because using Mann-Whitney U test for normally distributed data, out of laziness to check the normality, might produce a completely wrong result. 

For that we'll use the {normality} function from {dlookr} package, which conducts Shapiro-Wilk normality tests with every group. Low p-value in one of the group is enough to conclude that our data is not-normally distributed, so now we are sure that using a **Mann-Whitney U test** is a right choice.

![](not_normal.png)

```{r}
# install.packages("dlookr")
library(dlookr)
d %>% 
  group_by(jobclass) %>% 
  normality(wage)
```


## Compute Mann-Whitney U Test 

And the best way to compute our test (in my opinion) is the {ggbetweenstats} function from {ggstatsplot} package, which needs only 4 arguments:

- first, **our data** - d, with
- **x** - as the grouping variable - jobclass, and
- **y** - being salaries 
- finally, since our data is not-normally distributed, we'll choose a **nonparametric type** of statistical approach, and {ggbetweenstats} automatically uses Mann-Whitney U Test for comparing two groups.

Such simple command results in this statistically rich and publication ready plot! Now, let's interpret the results.

```{r}
# install.packages("ggstatsplot")
library(ggstatsplot)

ggbetweenstats(
  data = d,
  x    = jobclass, 
  y    = wage, 
  type = "nonparametric")

ggsave(filename = "mwu.jpg", plot = last_plot(), width = 6, height = 4)
```



## Interpret the result

- **W-statistics** explains why our test is sometimes called **Wilcoxon Rank Sum test**. Namely, 
  - the test first **ranks our data independently of the group**
  - then **sums the ranks for each group**, which IS the reason the test is called - **Rank Sum**
  - and finally, **sums of the ranks** are then used to calculate the **W-statistics**, where **W**-itself obviously originates from Wilcoxon, a scientist, who developed the test at roughly the same time as Mann and Whitney,
  - the **U-statistics** in **Mann-Whitney U** name is calculated slightly differently compared with W-statistics, but produces identical p-value


```{r}
d %>% 
  select(jobclass, wage) %>% 
  ungroup() %>% 
  mutate(wage_ranks = rank(wage)) %>% 
  group_by(jobclass) %>% 
  summarise(sum_ranks = sum(wage_ranks),
            n         = n()) %>% 
  mutate(W = sum_ranks - (n*(n+1))/2)
```

- and that's what both **W- and U-statistics** were previously used for - to look up a p-value in some table. But nowadays all statistical software compute p-values by default, so nobody cares about W- or U-statistics anymore. However, the **rank sums** which we just calculated are **incredibly useful** for understanding the test! And here is why:

![](critical_value.png)

- our **P-value** of 0.03 shows a moderate evidence against the Null Hypothesis (H~0~), that **groups are similar**, in favor of the alternative hypothesis (H~Alt~), that **groups differ**. This difference is often reported as a difference in medians, but here is the catch! **No medians were involved when we calculated sums of ranks!** The p-value shows whether there is a difference in sums of ranks, not medians! **The medians are simply more intuitive** then ranks for displaying the not-normally distributed nature of our data. And that is why, it can easily happen that medians are identical (especially with ordinal data), while samples are still significantly different. I panicked the first time I saw it ;) So, I hope you will not.

![](colbert-report-stephen-colbert.gif){width=50%}

All right, our P-value tells us that there is a difference between salaries of industrial and IT guys. However, **a P-value does not say how big this difference is**. Moreover, the difference in medians is also useless, because medians were not compared and could be identical. 


![](p_value_interpretation.png)

- fortunately, {ggbetweenstats} provides a **Rank biserial correlation coefficient** with 95% confidence intervals as the measure of the **effect size**, which shows how large the difference is. The {interpret_rank_biserial} function from {effectsize} package helps to interpret this effect size and even provides a reference. Our effect size of -0.47 indicates a **very large** difference in salaries between our groups.

```{r}
# install.packages("effectsize")
library(effectsize)

interpret_rank_biserial(-0.47)

?interpret_rank_biserial
```

![](interpter_rank_biserial.png){width=50%}

## Conclusion

So, as you can see, both the test itself and it's name are quite confusing. And I prefer to stay with **Mann-Whitney U name**, because **Wilcoxon Rank Sum Test** can be easily mistaken with the **Wilcoxon Signed-Rank Test**, which can only be applied for paired samples. People often say - they used **Wilcoxon** test, but when I ask "which of both they mean", they mostly don't know. **But it's very important to know!!!**, because otherwise, as the p-value shows, we can get a completely opposite result.

```{r}
wilcox.test(data = d, wage ~ jobclass)
wilcox.test(data = d, wage ~ jobclass, paired = T)
```

However, if your data is paired and you want to understand Paired Wilcoxon Test really well, check out the code below and [this video](https://youtu.be/YRlIkNKazF8).

```{r}
ggwithinstats(
  data = d,
  x    = jobclass, 
  y    = wage, 
  type = "nonparametric")
```






## Don't use two-samples Wilcoxon-test if:

- samples are small (n<30) and normally distributed (or big and near normal). In this case use the more powerful [two-samples t-test](https://yury-zablotski.netlify.com/post/two-sample-t-test-compare-your-work-to-others/)

- data is not-normally distributed and you have more then two groups to compare to, then use Kruskal-Wallis test

---

If you think, I missed something, please comment on it, and Iâ€™ll improve this tutorial.

**Thank you for learning!**




## References and useful links

- https://www.stat.auckland.ac.nz/~wild/ChanceEnc/Ch10.wilcoxon.pdf

- https://datatab.net/tutorial/mann-whitney-u-test